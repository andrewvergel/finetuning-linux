# Fine-tuning LoRA en Ubuntu + RTX 4060â€¯Ti

> Proyecto personal documentado como parte de mi portafolio. Implementa un flujo completo de fine-tuning con LoRA/QLoRA sobre modelos modernos (Qwen2.5-7B-Instruct) usando CUDA en Ubuntu, incluyendo preparaciÃ³n del entorno, entrenamiento reproducible y despliegue de inferencia.

## âœ¨ Resumen del Proyecto
- **Objetivo:** Entrenar un chatbot corporativo capaz de responder procedimientos internos a partir de un dataset de instrucciones propio.
- **TecnologÃ­as:** Python, PyTorch 2.0+, Transformers 4.40+, PEFT 0.10+, TRL, CUDA 12.1+.
- **Hardware:** NVIDIA RTX 4060â€¯Ti (16â€¯GB VRAM) en Ubuntu 22.04+.
- **CaracterÃ­sticas destacadas:**
  - Soporte para QLoRA 4-bit (optimizaciÃ³n de memoria)
  - Entrenamiento estable con bfloat16
  - Gradient Checkpointing y optimizaciones de memoria
  - Early Stopping y evaluaciÃ³n por pasos
  - Packing de secuencias opcional
- **Repositorio:** [`andrewvergel/finetuning-linux`](https://github.com/andrewvergel/finetuning-linux)

## ðŸ§± Arquitectura y Flujo
1. **Bootstrap de entorno** â€“ instalaciÃ³n de drivers, CUDA y dependencias en un equipo limpio.
2. **Dataset JSONL** â€“ prompts internos versionados en `data/instructions.jsonl`.
3. **Script de entrenamiento** â€“ `scripts/finetune_lora.py` (v1.1.1) realiza duplicaciÃ³n inteligente del dataset y ajusta hiperparÃ¡metros para escenarios de pocos datos.
4. **Inferencia controlada** â€“ `scripts/inference_lora.py` (v1.0.2) con decodificaciÃ³n determinista para evaluar resultados.
5. **Reportes** â€“ se genera `training_info.json` con metadatos del entrenamiento.

## ðŸš€ Puesta en Marcha desde Cero
```bash
# 1. Clonar el repositorio
git clone https://github.com/andrewvergel/finetuning-linux.git
cd finetuning-linux

# 2. Crear y activar entorno virtual
python3 -m venv .venv
source .venv/bin/activate

# 3. Instalar dependencias base
pip install --upgrade pip setuptools wheel
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 4. Instalar dependencias del proyecto
pip install "numpy<2.0" pyarrow==14.0.1
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128,expandable_segments:True
pip install -r requirements.txt
```
> ðŸ’¡ Si partes de un servidor reciÃ©n formateado, instala previamente los drivers NVIDIA, CUDA 12.1 y utilidades del sistema (detallado en secciones posteriores del repositorio original).
> ðŸ“¦ `requirements.txt` incluye todas las librerÃ­as auxiliares; aun asÃ­, instalamos `numpy<2.0` y `pyarrow==14.0.1` antes para evitar conflictos conocidos con `datasets` (error `PyExtensionType`).
> ðŸ” Antes de entrenar, puedes ejecutar `python scripts/validate_environment.py` para verificar versiones de Python, CUDA, VRAM disponible, dataset y dependencias.
> ðŸ§© Para modelos Qwen2.5 asegÃºrate de usar `transformers>=4.40` y `peft>=0.10` (ya fijados en `requirements.txt`).
> ðŸ§¾ Cada entrenamiento deja un log detallado en `logs/debug_last_run.log` con mÃ©tricas y respuestas de validaciÃ³n automÃ¡tica.

## ðŸ“š Dataset de Instrucciones
```bash
mkdir -p data
cat > data/instructions.jsonl << 'JSONL'
{"system":"Eres un asistente experto en procesos internos.","input":"Dame los pasos para conciliar pagos de los lunes.","output":"1) Exporta el CSV del banco.\n2) Ejecuta el job 'reconcile_monday'.\n3) Revisa discrepancias en la tabla 'recon_issues'."}
{"system":"Habla en tono profesional y conciso.","input":"Resume este procedimiento en tres bullets.","output":"â€¢ Exportar CSV.\nâ€¢ Ejecutar job.\nâ€¢ Validar discrepancias."}
{"system":"Responde siempre con pasos numerados.","input":"Â¿CÃ³mo abro un ticket de soporte?","output":"1) Entra al helpdesk.\n2) Crea ticket 'Incidente'.\n3) Adjunta evidencias."}
JSONL
```
> â„¹ï¸ `data/instructions.jsonl` **ya viene versionado en este repositorio** y es el Ãºnico archivo permitido dentro de `data/`. El script de entrenamiento duplica automÃ¡ticamente el dataset si detecta menos de 200 muestras, pero se recomienda ampliarlo manualmente con mÃ¡s casuÃ­sticas para mejorar la diversidad de respuestas.

## ðŸ› ï¸ Script de Entrenamiento (`scripts/finetune_lora.py` v1.2.0)

### CaracterÃ­sticas Principales
- **Modelo Base:** `Qwen/Qwen2.5-7B-Instruct` por defecto (soporta cualquier modelo compatible con Transformers)
- **Optimizaciones de Memoria:**
  - QLoRA 4-bit activable vÃ­a `FT_USE_QLORA=1`
  - Gradient Checkpointing
  - bfloat16 por defecto (Ã³ptimo para GPUs Ada/Lovelace)
  - Packing de secuencias opcional (`FT_FORCE_PACKING`)
- **Entrenamiento Estable:**
  - Early Stopping basado en pÃ©rdida de validaciÃ³n
  - EvaluaciÃ³n por pasos configurables (`FT_EVAL_STEPS`)
  - Guardado de checkpoints incremental
  - Logs detallados en `logs/debug_last_run.log`
- **ConfiguraciÃ³n Flexible:**
  - Todas las opciones configurables mediante variables de entorno `FT_*`
  - Soporte para mÃºltiples objetivos LoRA
  - Batch size y acumulaciÃ³n de gradientes configurables

### Flujo de Entrenamiento
1. Carga y validaciÃ³n del dataset desde `data/instructions.jsonl`
2. DivisiÃ³n automÃ¡tica entrenamiento/validaciÃ³n (85/15% por defecto)
3. Carga del modelo base con optimizaciones de memoria
4. AplicaciÃ³n de LoRA/QLoRA segÃºn configuraciÃ³n
5. Entrenamiento con monitoreo de mÃ©tricas
6. EvaluaciÃ³n periÃ³dica y guardado de checkpoints
7. GeneraciÃ³n de informe final con ejemplos de inferencia

### ðŸ§¾ ConfiguraciÃ³n Recomendada (`.env`)

```bash
# Modelo y Datos
FT_MODEL_ID=Qwen/Qwen2.5-7B-Instruct
FT_DATA_PATH=data/instructions.jsonl
FT_OUT_DIR=models/out-qlora
FT_TRUST_REMOTE_CODE=1  # Requerido para Qwen2.5

# OptimizaciÃ³n de Memoria
FT_USE_QLORA=1           # Activar QLoRA 4-bit
FT_FORCE_PACKING=0       # Desactivar packing por defecto (mÃ¡s memoria)
FT_GRADIENT_CHECKPOINTING=1

# HiperparÃ¡metros de Entrenamiento
FT_PER_DEVICE_BATCH_SIZE=1
FT_GRADIENT_ACCUMULATION=8
FT_NUM_EPOCHS=5
FT_LEARNING_RATE=2e-5
FT_WARMUP_RATIO=0.1
FT_LR_SCHEDULER=cosine_with_restarts
FT_WEIGHT_DECAY=0.02

# ConfiguraciÃ³n LoRA
FT_LORA_RANK=8
FT_LORA_ALPHA=16
FT_LORA_DROPOUT=0.05
FT_LORA_TARGET_MODULES=q_proj,v_proj

# ValidaciÃ³n y Guardado
FT_EVAL_STEPS=25
FT_SAVE_STEPS=25
FT_SAVE_TOTAL_LIMIT=2
FT_EVAL_MAX_NEW_TOKENS=128
FT_EVAL_SAMPLE_SIZE=3

# Otros
FT_LOGGING_STEPS=10
FT_DATASET_SHUFFLE_SEED=42
FT_VALIDATION_SPLIT=0.15
FT_DEBUG_LOG_FILE=debug_last_run.log
```
> Duplica el archivo como `.env` y personaliza los valores si necesitas cambiar cualquier hiperparÃ¡metro sin editar el script.

### ðŸ” InterpretaciÃ³n de logs y tuning
#### PÃ©rdida de entrenamiento
- Valores de `loss` entre **4.0â€“5.0** son tÃ­picos para DialoGPT con datasets repetidos. Si cae de ~5.2 a ~4.1 en pocas Ã©pocas, la convergencia va bien. Si la pÃ©rdida se estanca >3.8 tras 20 Ã©pocas, considera subir `LEARNING_RATE` o reducir `LORA_DROPOUT`.
#### Learning rate efectivo
- Con `LEARNING_RATE = 4e-5` deberÃ­as ver valores ~3.9e-05 a 4.0e-05 en los logs. Si cae demasiado rÃ¡pido (<3e-05) en las primeras Ã©pocas, sube `WARMUP_RATIO`.
#### SeÃ±ales de overfitting
- PÃ©rdida de entrenamiento baja, pero validaciÃ³n no mejora o sube â†’ sube `LORA_DROPOUT` o baja `NUM_EPOCHS`.
#### Si el modelo delira
- Repite frases, respuestas circulares o incoherentes â†’ sube `LORA_DROPOUT` a 0.2, baja `NUM_EPOCHS` a 20, y aÃ±ade mÃ¡s ejemplos Ãºnicos al dataset.

#### Fases avanzadas del entrenamiento (Ã©pocas 20+)
- Si ves `loss` ~2.0 estable y `learning_rate` ~3e-06, el modelo estÃ¡ cerca del mÃ­nimo. 
- Continuar entrenando puede llevar a **overfitting sutil** (responde mejor a ejemplos de entrenamiento pero falla en variaciones). 
- **Criterio de parada:** si `eval_loss` deja de bajar por 3â€“4 Ã©pocas seguidas, detÃ©n el entrenamiento. 
- **Si necesitas mÃ¡s calidad:** en lugar de mÃ¡s Ã©pocas, amplÃ­a el dataset real (no repitas) o prueba un modelo base mayor.

#### âœ… SeÃ±ales de progreso saludable (Ã©pocas 1â€“5)
- `learning_rate` deberÃ­a subir de ~6e-06 a ~3e-05 durante las primeras Ã©pocas (indica warmup funcionando).
- `eval_loss` debe bajar de forma consistente (ej.: 7.8 â†’ 6.9 entre Ã©poca 1 y 3).
- `loss` de entrenamiento entre 7.0â€“8.5 al inicio, bajando gradualmente.

### ðŸŽ¯ GuÃ­a de Ajuste de HiperparÃ¡metros

#### OptimizaciÃ³n de Memoria (RTX 4060 Ti 16GB)
- **`FT_USE_QLORA` (1):** Activa cuantizaciÃ³n 4-bit (recomendado para modelos >7B)
- **`FT_PER_DEVICE_BATCH_SIZE` (1):** Mantener en 1 para mÃ¡xima estabilidad
- **`FT_GRADIENT_ACCUMULATION` (8):** Ajustar segÃºn VRAM disponible (mÃ¡s alto = mejor uso de GPU)
- **`FT_FORCE_PACKING` (0):** Desactivado por defecto (usa mÃ¡s memoria pero mÃ¡s estable)

#### Rendimiento del Entrenamiento
- **`FT_LORA_RANK` (8):** DimensiÃ³n de las matrices de bajo rango
  - *Aumentar* (16-32) para tareas complejas
  - *Reducir* (4-8) si hay problemas de memoria
- **`FT_LEARNING_RATE` (2e-5):** Tasa de aprendizaje base
  - *Aumentar* (3e-5) si la pÃ©rdida se estanca
  - *Reducir* (1e-5) si la pÃ©rdida es inestable
- **`FT_LORA_ALPHA` (16):** Factor de escalado (normalmente 2Ã— rank)

#### RegularizaciÃ³n
- **`FT_LORA_DROPOUT` (0.05):** RegularizaciÃ³n para evitar sobreajuste
  - *Aumentar* (0.1-0.2) si el modelo memoriza
  - *Reducir* (0.01) si el aprendizaje es lento
- **`FT_WEIGHT_DECAY` (0.02):** Decaimiento de pesos
  - *Aumentar* (0.05) para mÃ¡s regularizaciÃ³n
  - *Reducir* (0.01) si el modelo no converge

#### EvaluaciÃ³n
- **`FT_EVAL_STEPS` (25):** Frecuencia de evaluaciÃ³n
- **`FT_EVAL_SAMPLE_SIZE` (3):** NÃºmero de ejemplos para evaluaciÃ³n rÃ¡pida
- **`FT_EVAL_MAX_NEW_TOKENS` (128):** Longitud mÃ¡xima de generaciÃ³n en evaluaciÃ³n

## ðŸ’¬ Script de Inferencia (`scripts/inference_lora.py`)
- Carga el adaptador LoRA desde `models/out-tinyllama-lora`.
- Usa decodificaciÃ³n determinista (sin muestreo) para validar fÃ¡cilmente regresiones.
- Incluye loop interactivo opcional y estadÃ­sticas de uso de GPU.

## â–¶ï¸ EjecuciÃ³n
```bash
# Entrenamiento
python scripts/finetune_lora.py

# Inferencia inicial
python scripts/inference_lora.py
```
> El entrenamiento guarda pesos LoRA en `models/out-tinyllama-lora`. Puedes fusionarlos con el modelo base usando `scripts/merge_adapter.py` si necesitas un Ãºnico checkpoint.

## ðŸ§© Estructura del Proyecto
```
finetuning-linux/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ instructions.jsonl           # Dataset versionado
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ debug_last_run.log          # Log detallado del Ãºltimo entrenamiento
â”œâ”€â”€ models/                          # Salidas de entrenamiento (ignorado en git)
â”‚   â””â”€â”€ out-qlora/                  # Checkpoints del modelo
â”‚       â”œâ”€â”€ adapter_model.bin       # Pesos del adaptador LoRA
â”‚       â”œâ”€â”€ config.json             # ConfiguraciÃ³n del modelo
â”‚       â””â”€â”€ training_info.json      # MÃ©tricas y metadatos
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ finetune_lora.py            # Entrenamiento LoRA/QLoRA (v1.2.0)
â”‚   â”œâ”€â”€ inference_lora.py           # Inferencia con adaptadores
â”‚   â”œâ”€â”€ merge_adapter.py            # FusiÃ³n de adaptadores con el modelo base
â”‚   â””â”€â”€ validate_environment.py     # VerificaciÃ³n del entorno
â”œâ”€â”€ .env.example                    # Plantilla de configuraciÃ³n
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                       # Este documento
```